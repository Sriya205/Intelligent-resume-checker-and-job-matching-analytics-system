{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Resume Screening and Job Matching Analytics\n",
    "\n",
    "This notebook provides analysis and insights into the resume screening system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "resumes_df = pd.read_csv('../data/raw/resume_dataset.csv')\n",
    "jobs_df = pd.read_csv('../data/raw/job_description_dataset.csv')\n",
    "\n",
    "print(\"Resume Dataset Shape:\", resumes_df.shape)\n",
    "print(\"Job Dataset Shape:\", jobs_df.shape)\n",
    "print(\"\\nResume Dataset Columns:\", list(resumes_df.columns))\n",
    "print(\"Job Dataset Columns:\", list(jobs_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Resume Statistics:\")\n",
    "print(resumes_df.describe())\n",
    "print(\"\\nJob Statistics:\")\n",
    "print(jobs_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experience distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "resumes_df['experience_level'].value_counts().plot(kind='bar')\n",
    "plt.title('Resume Experience Level Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "jobs_df['experience_level'].value_counts().plot(kind='bar')\n",
    "plt.title('Job Experience Level Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze skills\n",
    "from collections import Counter\n",
    "\n",
    "# Flatten skills from resumes\n",
    "all_resume_skills = []\n",
    "for skills in resumes_df['skills']:\n",
    "    if isinstance(skills, str):\n",
    "        all_resume_skills.extend([s.strip() for s in skills.split(',')])\n",
    "\n",
    "resume_skill_counts = Counter(all_resume_skills)\n",
    "\n",
    "# Flatten skills from jobs\n",
    "all_job_skills = []\n",
    "for skills in jobs_df['required_skills']:\n",
    "    if isinstance(skills, str):\n",
    "        all_job_skills.extend([s.strip() for s in skills.split(',')])\n",
    "\n",
    "job_skill_counts = Counter(all_job_skills)\n",
    "\n",
    "# Plot top skills\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "top_resume_skills = dict(resume_skill_counts.most_common(10))\n",
    "plt.bar(top_resume_skills.keys(), top_resume_skills.values())\n",
    "plt.title('Top 10 Skills in Resumes')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "top_job_skills = dict(job_skill_counts.most_common(10))\n",
    "plt.bar(top_job_skills.keys(), top_job_skills.values())\n",
    "plt.title('Top 10 Required Skills in Jobs')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze model performance\n",
    "from src.ml.evaluate import load_model, evaluate_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Create test data (simplified)\n",
    "test_data = []\n",
    "for _, resume in resumes_df.head(20).iterrows():\n",
    "    for _, job in jobs_df.head(10).iterrows():\n",
    "        combined_text = resume['resume_text'] + \" \" + job['job_description']\n",
    "        resume_skills = set(resume['skills'].split(', '))\n",
    "        job_skills = set(job['required_skills'].split(', '))\n",
    "        label = 1 if len(resume_skills.intersection(job_skills)) > 0 else 0\n",
    "        test_data.append({\"text\": combined_text, \"label\": label})\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Evaluate model\n",
    "eval_results = evaluate_model(X_test, y_test)\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(f\"Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "print(f\"Precision: {eval_results['precision']:.4f}\")\n",
    "print(f\"Recall: {eval_results['recall']:.4f}\")\n",
    "print(f\"F1 Score: {eval_results['f1_score']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(eval_results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model()\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Match', 'Match'], \n",
    "            yticklabels=['No Match', 'Match'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze match predictions\n",
    "from src.ml.predict import predict_match\n",
    "\n",
    "# Sample predictions\n",
    "sample_matches = []\n",
    "for i in range(min(10, len(resumes_df))):\n",
    "    resume = resumes_df.iloc[i]\n",
    "    job = jobs_df.iloc[i % len(jobs_df)]\n",
    "    \n",
    "    score = predict_match(resume['resume_text'], job['job_description'])\n",
    "    sample_matches.append({\n",
    "        'resume_id': resume['id'],\n",
    "        'job_id': job['id'],\n",
    "        'match_score': score,\n",
    "        'resume_title': resume['name'],\n",
    "        'job_title': job['title']\n",
    "    })\n",
    "\n",
    "matches_df = pd.DataFrame(sample_matches)\n",
    "print(\"Sample Match Predictions:\")\n",
    "print(matches_df.sort_values('match_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize match score distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(matches_df['match_score'], bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Match Scores')\n",
    "plt.xlabel('Match Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_data = []\n",
    "for _, match in matches_df.iterrows():\n",
    "    resume = resumes_df[resumes_df['id'] == match['resume_id']].iloc[0]\n",
    "    job = jobs_df[jobs_df['id'] == match['job_id']].iloc[0]\n",
    "    \n",
    "    resume_exp = {'Entry Level': 1, 'Mid Level': 2, 'Senior Level': 3, 'Lead': 4, 'Principal': 5}.get(resume['experience_level'], 1)\n",
    "    job_exp = {'Entry Level': 1, 'Mid Level': 2, 'Senior Level': 3, 'Lead': 4, 'Principal': 5}.get(job['experience_level'], 1)\n",
    "    \n",
    "    correlation_data.append({\n",
    "        'match_score': match['match_score'],\n",
    "        'experience_match': 1 if resume_exp >= job_exp else 0,\n",
    "        'salary': job['salary']\n",
    "    })\n",
    "\n",
    "corr_df = pd.DataFrame(correlation_data)\n",
    "correlation_matrix = corr_df.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive analysis of the resume screening system including:\n",
    "- Dataset exploration and statistics\n",
    "- Skills analysis\n",
    "- Model performance evaluation\n",
    "- Match prediction analysis\n",
    "- Correlation insights\n",
    "\n",
    "Key findings:\n",
    "- [Add your key insights here based on the analysis]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
